from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import streamlit as st
import time
import re
from ollama import chat, ChatResponse
from openai import OpenAI
from io import BytesIO

# è€ƒè¯•å¤§çº²ç”Ÿæˆå‡½æ•°
def generate_outline(exam_content, subject, iterations=2):
    outline = ""
    progress_bar = st.progress(0)
    
    for i in range(iterations):
        progress_bar.progress((i + 1) / iterations)
        time.sleep(0.5)  # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
        
        # æå–é¢˜ç›®ä¿¡æ¯
        questions = re.findall(r'### é¢˜ç›®\d+\n\*\*é¢˜å‹\*\*:(.+?)\n\*\*é¢˜ç›®å†…å®¹\*\*:(.+?)\n\*\*ç­”é¢˜è¦æ±‚\*\*:(.+?)\n\*\*åˆ†å€¼\*\*:(.+?)\n', exam_content, re.DOTALL)
        
        # æ„å»ºå¤§çº²å†…å®¹
        outline = f"{subject}è€ƒè¯•å¤§çº² (è¿­ä»£{i+1}/{iterations})\n\n"
        outline += "ğŸ“Œ ä¸€ã€è€ƒè¯•æ¦‚å†µ\n"
        outline += f"ğŸ”¹ ç§‘ç›®: {subject}\n"
        outline += f"ğŸ”¹ é¢˜ç›®æ€»æ•°: {len(questions)}\n"
        outline += f"ğŸ”¹ æ€»åˆ†: 100åˆ†\n\n"
        
        outline += "ğŸ“Š äºŒã€é¢˜å‹åˆ†å¸ƒ\n"
        type_counts = {}
        for q in questions:
            q_type = q[0].strip()
            type_counts[q_type] = type_counts.get(q_type, 0) + 1
        for t, count in type_counts.items():
            outline += f"âœ… {t}: {count}é¢˜\n"
        outline += "\n"
        
        outline += "ğŸ§  ä¸‰ã€çŸ¥è¯†ç‚¹åˆ†å¸ƒ\n"
        topics = get_subject_topics(subject)
        outline += " | ".join([f"ğŸ“Œ{t}" for t in topics]) + "\n\n"
        
        outline += "ğŸ“ å››ã€é¢˜ç›®è¦æ±‚\n"
        for i, q in enumerate(questions, 1):
            outline += f"{i}. {q[1].strip()} â­åˆ†å€¼: {q[3].strip()}\n"
        
        outline += "\nğŸ¯ äº”ã€è¯„åˆ†æ ‡å‡†\n"
        outline += "1. ğŸ“ æŒ‰æ­¥éª¤ç»™åˆ†\n"
        outline += "2. âœ”ï¸ ç­”æ¡ˆå‡†ç¡®å®Œæ•´\n"
        outline += "3. ğŸ“š ç¬¦åˆå­¦ç§‘è§„èŒƒ\n"
    
    progress_bar.empty()
    return outline
# PDFç”Ÿæˆå‡½æ•°ï¼ˆæ”¾åœ¨æœ€å‰é¢ï¼‰
def generate_pdf(content, subject):
    try:
        # æ³¨å†Œä¸­æ–‡å­—ä½“ï¼ˆä½¿ç”¨ç³»ç»Ÿè‡ªå¸¦æˆ–æŒ‡å®šè·¯å¾„ï¼‰
        try:
            pdfmetrics.registerFont(TTFont('SimSun', 'simsun.ttc'))
        except:
            st.warning("æœªæ‰¾åˆ°SimSunå­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
        
        # åˆ›å»ºPDF
        buffer = BytesIO()
        c = canvas.Canvas(buffer, pagesize=A4)
        width, height = A4
        
        # è®¾ç½®å­—ä½“ï¼ˆç®€åŒ–å¤„ç†ï¼Œä¸ä½¿ç”¨Boldå˜ä½“ï¼‰
        try:
            font_name = "SimSun"
            pdfmetrics.registerFont(TTFont(font_name, "simsun.ttc"))
            c.setFont(font_name, 12)
        except:
            font_name = "Helvetica"
            c.setFont(font_name, 12)
        
        # æ·»åŠ æ ‡é¢˜ï¼ˆä½¿ç”¨å¸¸è§„å­—ä½“åŠ ç²—æ•ˆæœï¼‰
        c.setFont(font_name, 14)
        c.drawCentredString(width/2, height-50, f"{subject}è¯•å·")
        c.setFont(font_name, 12)
        
        # æ·»åŠ å†…å®¹
        y_position = height - 80
        for line in content.split("\n"):
            if y_position < 50:  # æ¢é¡µåˆ¤æ–­
                c.showPage()
                y_position = height - 50
            
            if line.startswith("###"):
                # ä½¿ç”¨å­—å·åŠ ç²—æ•ˆæœæ›¿ä»£Boldå­—ä½“
                c.setFont(font_name, 14)
                c.drawString(50, y_position, line.replace("###", "").strip())
                y_position -= 20
                c.setFont(font_name, 12)
            else:
                text = c.beginText(50, y_position)
                text.textLine(line)
                c.drawText(text)
                y_position -= 15
        
        c.save()
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes
        
    except Exception as e:
        st.error(f"ç”ŸæˆPDFå¤±è´¥: {str(e)}")
        return b''



# ç§‘ç›®ä¸»é¢˜æ˜ å°„
def get_subject_topics(subject):
    topics_map = {
        "è¯­æ–‡": ["å¤è¯—æ–‡", "ç°ä»£æ–‡é˜…è¯»", "ä½œæ–‡", "æ–‡è¨€æ–‡", "ä¿®è¾æ‰‹æ³•", "ç°ä»£æ±‰è¯­", "å¤ä»£æ±‰è¯­"],
        "æ•°å­¦": ["ä»£æ•°", "å‡ ä½•", "å‡½æ•°", "æ¦‚ç‡ç»Ÿè®¡", "æ–¹ç¨‹", "ä¸ç­‰å¼", "ä¸‰è§’å‡½æ•°"],
        "è‹±è¯­": ["reading", "writing", "grammar", "vocabulary", "listening", "speaking"],
        "ç‰©ç†": ["åŠ›å­¦", "ç”µå­¦", "å…‰å­¦", "çƒ­å­¦", "åŸå­ç‰©ç†", "ç”µç£å­¦", "åŠ¨åŠ›å­¦"],
        "åŒ–å­¦": ["æ— æœºåŒ–å­¦", "æœ‰æœºåŒ–å­¦", "åŒ–å­¦ååº”", "åŒ–å­¦æ–¹ç¨‹å¼", "å®éªŒ", "åˆ†å­ç»“æ„", "åŒ–å­¦é”®"]
    }
    return topics_map.get(subject, [])

def get_other_subject_keywords(subject):
    other_subjects = {
        "è¯­æ–‡": ["equation", "chemical", "physics", "math", "calculate"],
        "æ•°å­¦": ["æ–‡è¨€æ–‡", "ä½œæ–‡", "åŒ–å­¦å¼", "ç‰©ç†å…¬å¼", "è‹±è¯­å•è¯"],
        "è‹±è¯­": ["å¤è¯—", "æ–¹ç¨‹å¼", "åŒ–å­¦ååº”", "ç‰©ç†å®éªŒ", "æ•°å­¦å…¬å¼"],
        "ç‰©ç†": ["å¤è¯—æ–‡", "ä½œæ–‡", "åŒ–å­¦å¼", "è‹±è¯­å•è¯", "ä»£æ•°"],
        "åŒ–å­¦": ["å¤è¯—æ–‡", "ä½œæ–‡", "ç‰©ç†å…¬å¼", "è‹±è¯­å•è¯", "å‡ ä½•"]
    }
    return other_subjects.get(subject, [])

# é¡µé¢è®¾ç½®
st.set_page_config(page_title="AIæ¨¡å‹è°ƒç”¨å·¥å…·", layout="wide")
st.title("AIæ¨¡å‹è°ƒç”¨å·¥å…·")

# æ¨¡å‹é€‰æ‹©
model_option = st.selectbox(
    "é€‰æ‹©æ¨¡å‹",
    ("ollama (deepseek-r1:8b)", "deepseek (deepseek-reasoner)","ollama (deepseek-r1:1.5b)"),
    index=0
)

# è¯•å·å‚æ•°è®¾ç½®
st.subheader("è¯•å·å‚æ•°è®¾ç½®")
col1, col2 = st.columns(2)
with col1:
    subject = st.selectbox("ç§‘ç›®", ["è¯­æ–‡", "æ•°å­¦", "è‹±è¯­", "ç‰©ç†", "åŒ–å­¦"], index=0)
    difficulty = st.select_slider("éš¾åº¦", ["ç®€å•", "ä¸­ç­‰", "å›°éš¾"], value="ä¸­ç­‰")
    
with col2:
    question_count = st.slider("æ€»é¢˜æ•°", 5, 30, 10)
    outline_iterations = st.slider("å¤§çº²è¿­ä»£æ¬¡æ•°", 1, 5, 2, 
                                 help="å¢åŠ è¿­ä»£æ¬¡æ•°å¯ä»¥ä¼˜åŒ–å¤§çº²è´¨é‡")
    st.write("å„é¢˜å‹æ•°é‡åˆ†é…:")
    
    # é¢˜å‹æ•°é‡åˆ†é…
    type_counts = {}
    available_types = ["é€‰æ‹©é¢˜", "å¡«ç©ºé¢˜", "è®¡ç®—é¢˜", "è§£ç­”é¢˜", "ä½œæ–‡é¢˜"]
    cols = st.columns(len(available_types))
    for i, q_type in enumerate(available_types):
        with cols[i]:
            type_counts[q_type] = st.number_input(
                f"{q_type}",
                min_value=0,
                max_value=question_count,
                value=0 if q_type == "ä½œæ–‡é¢˜" else min(3, question_count),
                step=1,
                key=f"type_{q_type}"
            )
    
    # éªŒè¯æ€»æ•°
    total = sum(type_counts.values())
    if total != question_count:
        st.warning(f"âš ï¸ é¢˜å‹æ•°é‡æ€»å’Œåº”ä¸º{question_count}ï¼Œå½“å‰ä¸º{total}")

# ç”Ÿæˆæç¤º
system_prompt = f"ä½ æ˜¯ä¸€åèµ„æ·±ä¸­å­¦{subject}æ•™å¸ˆï¼Œæ‹¥æœ‰10å¹´ä»¥ä¸Šå‡ºé¢˜ç»éªŒ"
user_prompt = f"""è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹è¦æ±‚ç”Ÿæˆ{subject}è¯•å·ï¼š

ä¸€ã€ã€ç§‘ç›®å¼ºåˆ¶è¦æ±‚ã€‘
1. æœ¬é¢˜åº“ä¸º{subject}ä¸“ç”¨ï¼Œç¦æ­¢å‡ºç°å…¶ä»–å­¦ç§‘å†…å®¹
2. æ‰€æœ‰é¢˜ç›®å¿…é¡»ä½¿ç”¨{subject}ä¸“ä¸šæœ¯è¯­å’Œè§„èŒƒè¡¨è¾¾
3. é¢˜ç›®å†…å®¹å¿…é¡»å±äºä»¥ä¸‹{subject}æ ¸å¿ƒèŒƒç•´ï¼š
   - {', '.join(get_subject_topics(subject))}
4. ç¦æ­¢å‡ºç°ä»¥ä¸‹è·¨å­¦ç§‘å†…å®¹ï¼š
   - {', '.join(get_other_subject_keywords(subject))}

äºŒã€ã€è¯•å·è§„æ ¼ã€‘
â€¢ é¢˜ç›®æ€»æ•°ï¼š{question_count}é“ï¼ˆå¿…é¡»ç²¾ç¡®ï¼‰
â€¢ éš¾åº¦çº§åˆ«ï¼š{difficulty}
â€¢ é¢˜å‹åˆ†å¸ƒï¼ˆå¿…é¡»ä¸¥æ ¼æ‰§è¡Œï¼‰ï¼š
   {", ".join([f"â—‡ {k}: {v}é“" for k, v in type_counts.items() if v > 0])}
â€¢ æ€»åˆ†åˆ†å€¼ï¼š100åˆ†ï¼ˆå¿…é¡»ç²¾ç¡®ï¼‰

ä¸‰ã€ã€é¢˜ç›®ç”Ÿæˆè§„åˆ™ã€‘
1. é¢˜ç›®å”¯ä¸€æ€§ï¼šç¡®ä¿æ‰€æœ‰é¢˜ç›®å†…å®¹ä¸é‡å¤
2. éš¾åº¦ä¸€è‡´æ€§ï¼šæ‰€æœ‰é¢˜ç›®ä¿æŒç›¸åŒéš¾åº¦æ°´å¹³
3. ç¼–å·è¿ç»­æ€§ï¼šé¢˜ç›®ç¼–å·ä»1å¼€å§‹è¿ç»­é€’å¢
4. åˆ†å€¼è®¾ç½®ï¼šæ ¹æ®éš¾åº¦è®¾ç½®åˆç†åˆ†å€¼ï¼ˆ{difficulty}é¢˜ï¼š5-20åˆ†ï¼‰ï¼Œ
5. ç”Ÿæˆç­–ç•¥ï¼šæ¯æ¬¡ç”Ÿæˆ5é“é¢˜

å››ã€ã€é¢˜ç›®æ ¼å¼è§„èŒƒï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ã€‘
### é¢˜ç›®Xï¼ˆXä¸º1-{question_count}çš„ç¼–å·ï¼‰
**é¢˜å‹**ï¼š[å…·ä½“é¢˜å‹]
**é¢˜ç›®å†…å®¹**ï¼š[æ¸…æ™°è¡¨è¿°çš„å…·ä½“é—®é¢˜]
**é€‰é¡¹**ï¼š(ä»…é€‰æ‹©é¢˜éœ€è¦)
A) [é€‰é¡¹å†…å®¹]
B) [é€‰é¡¹å†…å®¹] 
C) [é€‰é¡¹å†…å®¹]
D) [é€‰é¡¹å†…å®¹]
**ç­”é¢˜è¦æ±‚**ï¼š[å…·ä½“è¦æ±‚ï¼Œå¦‚è®¡ç®—æ­¥éª¤ã€å­—æ•°é™åˆ¶ç­‰]
**åˆ†å€¼**ï¼š[æ•´æ•°åˆ†å€¼]
**ç­”æ¡ˆ**ï¼š[ç®€æ´å‡†ç¡®çš„å‚è€ƒç­”æ¡ˆï¼Œé€‰æ‹©é¢˜éœ€æ ‡æ³¨æ­£ç¡®é€‰é¡¹å¦‚"A"]

äº”ã€ã€ç”Ÿæˆç¤ºä¾‹ã€‘
### é¢˜ç›®1ï¼ˆ{subject}ç¤ºä¾‹ï¼‰
**é¢˜å‹**ï¼š{next(iter(type_counts.keys()), "é€‰æ‹©é¢˜")}
**é¢˜ç›®å†…å®¹**ï¼š[ç¬¦åˆ{subject}å­¦ç§‘çš„å…·ä½“é—®é¢˜]
**ç­”é¢˜è¦æ±‚**ï¼š[å…·ä½“è¦æ±‚ï¼Œå¦‚è®¡ç®—æ­¥éª¤ã€å­—æ•°é™åˆ¶ç­‰]
**åˆ†å€¼**ï¼š[æ•´æ•°åˆ†å€¼]
**ç­”æ¡ˆ**ï¼š[ç®€æ´å‡†ç¡®çš„å‚è€ƒç­”æ¡ˆ]

å…­ã€ã€ç‰¹åˆ«æŒ‡ä»¤ã€‘
1. ç”Ÿæˆå®Œæˆåï¼Œä¸¥æ ¼æ£€æŸ¥é¢˜ç›®æ•°é‡å’Œé¢˜å‹åˆ†å¸ƒ
2. ç¡®ä¿æ‰€æœ‰é¢˜ç›®å®Œå…¨ç¬¦åˆ{subject}å­¦ç§‘è§„èŒƒ
3. ç°åœ¨å¼€å§‹ç”Ÿæˆå‰{min(5, question_count)}é“é¢˜
"""

# æ·»åŠ ç§‘ç›®ç¤ºä¾‹å‡½æ•°
def get_subject_example(subject):
    examples = {
        "è¯­æ–‡": "åˆ†æã€Šå²³é˜³æ¥¼è®°ã€‹ä¸­'å…ˆå¤©ä¸‹ä¹‹å¿§è€Œå¿§ï¼Œåå¤©ä¸‹ä¹‹ä¹è€Œä¹'çš„ä¿®è¾æ‰‹æ³•åŠæ€æƒ³å†…æ¶µ",
        "æ•°å­¦": "å·²çŸ¥äºŒæ¬¡å‡½æ•°f(x)=xÂ²-4x+3ï¼Œæ±‚å…¶åœ¨åŒºé—´[0,4]çš„æœ€å°å€¼å’Œæœ€å¤§å€¼",
        "è‹±è¯­": "é˜…è¯»ä¸‹é¢çŸ­æ–‡ï¼Œé€‰æ‹©æœ€ä½³ç­”æ¡ˆ: 'The Eiffel Tower, __ is located in Paris, attracts millions of visitors each year.' A) which B) where C) when D) that",
        "ç‰©ç†": "è´¨é‡ä¸º2kgçš„ç‰©ä½“åœ¨æ°´å¹³é¢ä¸Šå—10Næ°´å¹³æ‹‰åŠ›ä½œç”¨ï¼Œæ‘©æ“¦ç³»æ•°ä¸º0.2ï¼Œæ±‚åŠ é€Ÿåº¦",
        "åŒ–å­¦": "å†™å‡ºä¹™çƒ¯ä¸æº´æ°´ååº”çš„åŒ–å­¦æ–¹ç¨‹å¼ï¼Œå¹¶è¯´æ˜ååº”ç±»å‹"
    }
    return examples.get(subject, "")

def get_subject_answer_example(subject):
    answers = {
        "è¯­æ–‡": "è¿ç”¨å¯¹å¶ä¿®è¾ï¼Œä½“ç°äº†ä½œè€…å¿§å›½å¿§æ°‘çš„å´‡é«˜æ€æƒ³å¢ƒç•Œ",
        "æ•°å­¦": "æœ€å°å€¼ï¼šf(2)= -1ï¼Œæœ€å¤§å€¼ï¼šf(4)=3",
        "è‹±è¯­": "A) which",
        "ç‰©ç†": "åŠ é€Ÿåº¦a=3m/sÂ²",
        "åŒ–å­¦": "CHâ‚‚=CHâ‚‚ + Brâ‚‚ â†’ CHâ‚‚BrCHâ‚‚Brï¼›åŠ æˆååº”"
    }
    return answers.get(subject, "")
# å¤„ç†å‡½æ•°
def process_request(model, system, user):
    if model.startswith("ollama"):
        model_name = model.split("(")[1].split(")")[0]  # ä»"ollama (deepseek-r1:8b)"æå–"deepseek-r1:8b"
        response: ChatResponse = chat(model=model_name, messages=[
            {'role': 'user', 'content': f'{system}ã€‚{user}'}
        ])
        content = response.message.content
        if "</think>" in content:
            parts = content.split("</think>")
            result = parts[1] if len(parts) > 1 else content
        else:
            result = content
        if "```" in result:
            result = result.split("```")[1] if len(result.split("```")) > 1 else result
    else:
        client = OpenAI(api_key="sk-4e843df1f877485f8c76bfcee461d3f7", 
                      base_url="https://api.deepseek.com")
        response = client.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            stream=False
        )
        result = response.choices[0].message.content
    return result

# çŠ¶æ€æ§åˆ¶
if 'running' not in st.session_state:
    st.session_state.running = False

# åœæ­¢æŒ‰é’®å›è°ƒ
def stop_execution():
    st.session_state.running = False

# æŒ‰é’®å¸ƒå±€
col1, col2 = st.columns(2)
with col1:
    submit_clicked = st.button("æäº¤")
with col2:
    st.button("åœæ­¢", on_click=stop_execution)

# åˆå§‹åŒ–ç”ŸæˆçŠ¶æ€
if 'generated' not in st.session_state:
    st.session_state.generated = False
if 'exam_content' not in st.session_state:
    st.session_state.exam_content = None
if 'submitted' not in st.session_state:
    st.session_state.submitted = False

# ä»…åœ¨ç‚¹å‡»æäº¤æŒ‰é’®åå¼€å§‹ç”Ÿæˆ
if submit_clicked:
    st.session_state.running = True
    st.session_state.submitted = True
    st.session_state.generated = False

if st.session_state.running and st.session_state.submitted and not st.session_state.generated:
    try:
        output = ""
        generated_questions = set()
        
        # ä¼˜åŒ–æ‰¹é‡ç”Ÿæˆç­–ç•¥
        chunk_size = min(10, question_count)  # å‡å°æ‰¹é‡å¤§å°æé«˜æˆåŠŸç‡
        chunks = [(i, min(i + chunk_size, question_count)) 
                 for i in range(0, question_count, chunk_size)]

        # ä¸¥æ ¼æŒ‰ç”¨æˆ·è¾“å…¥çš„é¢˜å‹æ•°é‡åˆ†é…
        question_types = []
        if total == question_count:  # æ•°é‡åŒ¹é…æ—¶æ‰ä½¿ç”¨ç”¨æˆ·è¾“å…¥
            for q_type, count in type_counts.items():
                question_types.extend([q_type] * count)
        else:  # æ•°é‡ä¸åŒ¹é…æ—¶è‡ªåŠ¨å¹³å‡åˆ†é…
            st.warning("âš ï¸ é¢˜å‹æ•°é‡æ€»å’Œä¸åŒ¹é…ï¼Œå·²è‡ªåŠ¨è°ƒæ•´åˆ†é…")
            base_count = question_count // len(type_counts)
            remainder = question_count % len(type_counts)
            question_types = []
            for i, q_type in enumerate(type_counts):
                count = base_count + (1 if i < remainder else 0)
                question_types.extend([q_type] * count)
        
        status_area = st.empty()
        current_question_num = 1
        max_retries = 5  # å¢åŠ é‡è¯•æ¬¡æ•°
        
        for start, end in chunks:
            if not st.session_state.running:
                st.warning("ç”Ÿæˆå·²ä¸­æ­¢")
                break
                
            retry_count = 0
            success = False
            
            while retry_count < max_retries and not success:
                try:
                    status_area.text(f"æ­£åœ¨ç”Ÿæˆé¢˜ç›® {current_question_num}-{min(current_question_num + chunk_size -1, question_count)}/{question_count} (å°è¯• {retry_count+1}/{max_retries})...")
                    
                    # åŠ¨æ€ç”Ÿæˆå½“å‰æ‰¹æ¬¡çš„é¢˜ç›®ç¼–å·
                    current_batch_size = min(chunk_size, question_count - current_question_num + 1)
                    batch_end = current_question_num + current_batch_size - 1
                    chunk_prompt = f"{user_prompt}\nè¯·ç”Ÿæˆé¢˜ç›®{current_question_num}-{batch_end}"
                    
                    partial_output = process_request(model_option, system_prompt, chunk_prompt)
                    
                    # å¢å¼ºé¢˜ç›®å®Œæ•´æ€§éªŒè¯
                    try:
                        # åˆ†å‰²é¢˜ç›®
                        raw_questions = re.split(r'### é¢˜ç›®\d+', partial_output)[1:]
                        if not raw_questions:
                            raise ValueError("æœªç”Ÿæˆä»»ä½•é¢˜ç›®")
                        
                        questions = []
                        for question in raw_questions:
                            try:
                                # ä¸¥æ ¼æ£€æŸ¥å¿…å¡«å­—æ®µ
                                required_fields = {
                                    "é¢˜å‹": r'(?:\*\*é¢˜å‹\*\*|é¢˜å‹)[ï¼š:].+',
                                    "é¢˜ç›®å†…å®¹": r'(?:\*\*é¢˜ç›®å†…å®¹\*\*|é¢˜ç›®å†…å®¹)[ï¼š:].+',
                                    "ç­”é¢˜è¦æ±‚": r'(?:\*\*ç­”é¢˜è¦æ±‚\*\*|ç­”é¢˜è¦æ±‚)[ï¼š:].+',
                                    "åˆ†å€¼": r'(?:\*\*åˆ†å€¼\*\*|åˆ†å€¼)[ï¼š:].+\d+åˆ†?',
                                    "ç­”æ¡ˆ": r'(?:\*\*ç­”æ¡ˆ\*\*|ç­”æ¡ˆ)[ï¼š:].+'
                                }
                                
                                # é¢˜å‹ç‰¹å®šæ£€æŸ¥
                                if q_type == "é€‰æ‹©é¢˜":
                                    if not re.search(r'[A-D]\)\s*.+', question):
                                        raise ValueError("é€‰æ‹©é¢˜å¿…é¡»åŒ…å«A-Dé€‰é¡¹")
                                    if not re.search(r'\*\*ç­”æ¡ˆ\*\*:\s*[A-D]', question):
                                        raise ValueError("é€‰æ‹©é¢˜ç­”æ¡ˆå¿…é¡»ä¸ºA-Dé€‰é¡¹")
                                        
                                elif q_type == "å¡«ç©ºé¢˜":
                                    if not re.search(r'_{3,}', question):
                                        raise ValueError("å¡«ç©ºé¢˜å¿…é¡»åŒ…å«å¡«ç©ºæ ‡è®°___")
                                    if not re.search(r'\*\*ç­”æ¡ˆ\*\*:\s*.+', question):
                                        raise ValueError("å¡«ç©ºé¢˜å¿…é¡»æä¾›ç­”æ¡ˆ")
                                        
                                elif q_type == "è§£ç­”é¢˜":
                                    if not re.search(r'\*\*ç­”é¢˜è¦æ±‚\*\*:.+æ­¥éª¤', question):
                                        raise ValueError("è§£ç­”é¢˜å¿…é¡»è¯´æ˜ç­”é¢˜æ­¥éª¤è¦æ±‚")
                                    if not re.search(r'\*\*ç­”æ¡ˆ\*\*:.+è¿‡ç¨‹', question):
                                        raise ValueError("è§£ç­”é¢˜ç­”æ¡ˆå¿…é¡»åŒ…å«è§£é¢˜è¿‡ç¨‹")
                                
                                missing_fields = []
                                for field, pattern in required_fields.items():
                                    if not re.search(pattern, question, re.DOTALL):
                                        missing_fields.append(field)
                                
                                if missing_fields:
                                    raise ValueError(f"é¢˜ç›®ç¼ºå°‘ä»¥ä¸‹å­—æ®µ: {', '.join(missing_fields)}")
                                
                                # æ£€æŸ¥é¢˜å‹ç‰¹å®šè¦æ±‚
                                q_type = question_types[current_question_num + len(questions) - 1]
                                if q_type == "é€‰æ‹©é¢˜":
                                    if not re.search(r'[A-D]\)\s*.+', question):
                                        raise ValueError(f"é¢˜ç›®åº”ä¸ºé€‰æ‹©é¢˜ä½†ç¼ºå°‘é€‰é¡¹")
                                    if re.search(r'_{3,}', question):
                                        raise ValueError(f"é€‰æ‹©é¢˜ä¸åº”åŒ…å«å¡«ç©ºæ ‡è®°")
                                elif q_type == "å¡«ç©ºé¢˜":
                                    if re.search(r'[A-D]\)\s*.+', question):
                                        raise ValueError(f"å¡«ç©ºé¢˜ä¸åº”åŒ…å«é€‰é¡¹")
                                    if not re.search(r'_{3,}', question):
                                        raise ValueError(f"å¡«ç©ºé¢˜ç¼ºå°‘å¡«ç©ºæ ‡è®°")
                                
                                # æ£€æŸ¥ç§‘ç›®å…³é”®è¯
                                subject_keywords = {
                                    "è¯­æ–‡": ["ä¿®è¾", "æ–‡è¨€", "ç°ä»£æ–‡", "ä½œæ–‡", "å¤è¯—"],
                                    "æ•°å­¦": ["å‡½æ•°", "æ–¹ç¨‹", "å‡ ä½•", "æ¦‚ç‡", "è®¡ç®—"],
                                    "è‹±è¯­": ["grammar", "reading", "writing", "vocabulary", "è‹±è¯­"],
                                    "ç‰©ç†": ["åŠ›å­¦", "ç”µå­¦", "å…‰å­¦", "çƒ­å­¦", "ç‰©ç†"],
                                    "åŒ–å­¦": ["ååº”", "åŒ–å­¦å¼", "å®éªŒ", "åˆ†å­", "åŒ–å­¦"]
                                }
                                
                                found_keywords = [
                                    keyword for keyword in subject_keywords[subject] 
                                    if re.search(keyword, question)
                                ]
                                
                                if not found_keywords:
                                    raise ValueError(f"é¢˜ç›®å†…å®¹ä¸ç¬¦åˆ{subject}å­¦ç§‘è¦æ±‚")
                                
                                questions.append(question)
                                
                            except ValueError as ve:
                                st.warning(f"é¢˜ç›®éªŒè¯å¤±è´¥: {str(ve)}")
                                continue
                                
                    except Exception as e:
                        st.error(f"é¢˜ç›®å¤„ç†å¤±è´¥: {str(e)}")
                        raise
                        
                        questions = []
                        for question in raw_questions:
                            # æ£€æŸ¥å¿…å¡«å­—æ®µ
                            required_fields = {
                                "é¢˜å‹": r'(?:\*\*é¢˜å‹\*\*|é¢˜å‹)[ï¼š:].+',
                                "é¢˜ç›®å†…å®¹": r'(?:\*\*é¢˜ç›®å†…å®¹\*\*|é¢˜ç›®å†…å®¹)[ï¼š:].+',
                                "ç­”é¢˜è¦æ±‚": r'(?:\*\*ç­”é¢˜è¦æ±‚\*\*|ç­”é¢˜è¦æ±‚)[ï¼š:].+',
                                "åˆ†å€¼": r'(?:\*\*åˆ†å€¼\*\*|åˆ†å€¼)[ï¼š:].+',
                                "ç­”æ¡ˆ": r'(?:\*\*ç­”æ¡ˆ\*\*|ç­”æ¡ˆ)[ï¼š:].+'
                            }
                            
                            missing_fields = []
                            for field, pattern in required_fields.items():
                                if not re.search(pattern, question, re.DOTALL):
                                    missing_fields.append(field)
                            
                            if missing_fields:
                                raise ValueError(f"é¢˜ç›®ç¼ºå°‘ä»¥ä¸‹å­—æ®µ: {', '.join(missing_fields)}")
                            
                            # æ£€æŸ¥é¢˜å‹ç‰¹å®šè¦æ±‚
                            q_type = question_types[current_question_num + len(questions) - 1]
                            if q_type == "é€‰æ‹©é¢˜":
                                if not re.search(r'[A-D]\)\s*.+', question):
                                    raise ValueError(f"é¢˜ç›®åº”ä¸ºé€‰æ‹©é¢˜ä½†ç¼ºå°‘é€‰é¡¹")
                                if re.search(r'_{3,}', question):
                                    raise ValueError(f"é€‰æ‹©é¢˜ä¸åº”åŒ…å«å¡«ç©ºæ ‡è®°")
                            elif q_type == "å¡«ç©ºé¢˜":
                                if re.search(r'[A-D]\)\s*.+', question):
                                    raise ValueError(f"å¡«ç©ºé¢˜ä¸åº”åŒ…å«é€‰é¡¹")
                                if not re.search(r'_{3,}', question):
                                    raise ValueError(f"å¡«ç©ºé¢˜ç¼ºå°‘å¡«ç©ºæ ‡è®°")
                            
                            # æ£€æŸ¥ç§‘ç›®å…³é”®è¯
                            subject_keywords = {
                                "è¯­æ–‡": ["ä¿®è¾", "æ–‡è¨€", "ç°ä»£æ–‡", "ä½œæ–‡", "å¤è¯—"],
                                "æ•°å­¦": ["å‡½æ•°", "æ–¹ç¨‹", "å‡ ä½•", "æ¦‚ç‡", "è®¡ç®—"],
                                "è‹±è¯­": ["grammar", "reading", "writing", "vocabulary", "è‹±è¯­"],
                                "ç‰©ç†": ["åŠ›å­¦", "ç”µå­¦", "å…‰å­¦", "çƒ­å­¦", "ç‰©ç†"],
                                "åŒ–å­¦": ["ååº”", "åŒ–å­¦å¼", "å®éªŒ", "åˆ†å­", "åŒ–å­¦"]
                            }
                            
                            found_keywords = [
                                keyword for keyword in subject_keywords[subject] 
                                if re.search(keyword, question)
                            ]
                            
                            if not found_keywords:
                                raise ValueError(f"é¢˜ç›®å†…å®¹ä¸ç¬¦åˆ{subject}å­¦ç§‘è¦æ±‚")
                            
                            questions.append(question)
                        
                        # éªŒè¯æ¯ä¸ªé¢˜ç›®
                        for i, question in enumerate(questions):
                            # æ£€æŸ¥å¿…å¡«å­—æ®µ
                            required_fields = {
                                "é¢˜å‹": r'(?:\*\*é¢˜å‹\*\*|é¢˜å‹)[ï¼š:].+',
                                "é¢˜ç›®å†…å®¹": r'(?:\*\*é¢˜ç›®å†…å®¹\*\*|é¢˜ç›®å†…å®¹)[ï¼š:].+',
                                "ç­”é¢˜è¦æ±‚": r'(?:\*\*ç­”é¢˜è¦æ±‚\*\*|ç­”é¢˜è¦æ±‚)[ï¼š:].+',
                                "åˆ†å€¼": r'(?:\*\*åˆ†å€¼\*\*|åˆ†å€¼)[ï¼š:].+',
                                "ç­”æ¡ˆ": r'(?:\*\*ç­”æ¡ˆ\*\*|ç­”æ¡ˆ)[ï¼š:].+'
                            }
                            
                            missing_fields = []
                            for field, pattern in required_fields.items():
                                if not re.search(pattern, question, re.DOTALL):
                                    missing_fields.append(field)
                            
                            if missing_fields:
                                raise ValueError(f"é¢˜ç›®{current_question_num+i}ç¼ºå°‘ä»¥ä¸‹å­—æ®µ: {', '.join(missing_fields)}")
                            
                            # æ£€æŸ¥é¢˜å‹ç‰¹å®šè¦æ±‚
                            q_type = question_types[current_question_num + i - 1]
                            if q_type == "é€‰æ‹©é¢˜":
                                if not re.search(r'[A-D]\)\s*.+', question):
                                    raise ValueError(f"é¢˜ç›®{current_question_num+i}åº”ä¸ºé€‰æ‹©é¢˜ä½†ç¼ºå°‘é€‰é¡¹")
                                if re.search(r'_{3,}', question):
                                    raise ValueError(f"é¢˜ç›®{current_question_num+i}ä¸ºé€‰æ‹©é¢˜ä¸åº”åŒ…å«å¡«ç©ºæ ‡è®°")
                            elif q_type == "å¡«ç©ºé¢˜":
                                if re.search(r'[A-D]\)\s*.+', question):
                                    raise ValueError(f"é¢˜ç›®{current_question_num+i}ä¸ºå¡«ç©ºé¢˜ä¸åº”åŒ…å«é€‰é¡¹")
                                if not re.search(r'_{3,}', question):
                                    raise ValueError(f"é¢˜ç›®{current_question_num+i}ç¼ºå°‘å¡«ç©ºæ ‡è®°")
                            
                            # æ£€æŸ¥ç§‘ç›®å…³é”®è¯
                            subject_keywords = {
                                "è¯­æ–‡": ["ä¿®è¾", "æ–‡è¨€", "ç°ä»£æ–‡", "ä½œæ–‡", "å¤è¯—"],
                                "æ•°å­¦": ["å‡½æ•°", "æ–¹ç¨‹", "å‡ ä½•", "æ¦‚ç‡", "è®¡ç®—"],
                                "è‹±è¯­": ["grammar", "reading", "writing", "vocabulary", "è‹±è¯­"],
                                "ç‰©ç†": ["åŠ›å­¦", "ç”µå­¦", "å…‰å­¦", "çƒ­å­¦", "ç‰©ç†"],
                                "åŒ–å­¦": ["ååº”", "åŒ–å­¦å¼", "å®éªŒ", "åˆ†å­", "åŒ–å­¦"]
                            }
                            
                            found_keywords = [
                                keyword for keyword in subject_keywords[subject] 
                                if re.search(keyword, question)
                            ]
                            
                            if not found_keywords:
                                raise ValueError(
                                    f"é¢˜ç›®{current_question_num+i}å†…å®¹ä¸ç¬¦åˆ{subject}å­¦ç§‘è¦æ±‚"
                                )
                        
                    # å®Œå…¨é‡å†™é¢˜ç›®ç¼–å·ç³»ç»Ÿ
                    raw_questions = re.split(r'### é¢˜ç›®\d+', partial_output)[1:]
                    valid_questions = []
                    
                    # é¢„å¤„ç†ï¼šæå–æœ‰æ•ˆé¢˜ç›®
                    for question in raw_questions:
                        # æ ¹æ®é¢˜å‹æå–å†…å®¹
                        if question_types[current_question_num + i - 1] == "é€‰æ‹©é¢˜":
                            pure_content = re.sub(
                                r'(^\s*|\*\*ç­”æ¡ˆ\*\*:.*|\bé¢˜ç›®\d+\b)', 
                                '', 
                                question, 
                                flags=re.DOTALL
                            ).strip()
                        else:
                            pure_content = re.sub(
                                r'(^\s*|\*\*ç­”æ¡ˆ\*\*:.*|\bé¢˜ç›®\d+\b|[A-D]\)\s*.+)', 
                                '', 
                                question, 
                                flags=re.DOTALL
                            ).strip()
                        
                        # éªŒè¯é¢˜ç›®å†…å®¹å®Œæ•´æ€§
                        required_parts = ["é¢˜ç›®å†…å®¹", "ç­”é¢˜è¦æ±‚", "åˆ†å€¼", "ç­”æ¡ˆ"]
                        if (pure_content and 
                            pure_content not in generated_questions and
                            all(part in question for part in required_parts)):
                            # æå–ç­”æ¡ˆéƒ¨åˆ†
                            answer = re.search(r'\*\*ç­”æ¡ˆ\*\*:(.*)', question, flags=re.DOTALL)
                            valid_questions.append({
                                'content': pure_content,
                                'answer': answer.group(1) if answer else ""
                            })
                            generated_questions.add(pure_content)
                    
                    # åŠ¨æ€ç”Ÿæˆè¿ç»­ç¼–å·é¢˜ç›®
                    fixed_output = ""
                    for i, q in enumerate(valid_questions):
                        question_num = current_question_num + i
                        fixed_question = f"### é¢˜ç›®{question_num}\n{q['content']}"
                        if q['answer']:
                            fixed_question += f"\n**ç­”æ¡ˆ**:{q['answer']}"
                        
                        if fixed_output:
                            fixed_output += "\n\n" + fixed_question
                        else:
                            fixed_output = fixed_question
                    
                    # æ›´æ–°å½“å‰é¢˜ç›®ç¼–å·
                    if valid_questions:
                        current_question_num += len(valid_questions)
                    
                    if fixed_output:
                        output += "\n\n" + fixed_output if output else fixed_output
                        success = True
                    else:
                        raise ValueError("æ‰€æœ‰é¢˜ç›®éƒ½é‡å¤")
                    
                except Exception as e:
                    retry_count += 1
                    if retry_count >= max_retries:
                        st.error(f"ç”Ÿæˆé¢˜ç›®{current_question_num}-{batch_end}å¤±è´¥: {str(e)}")
                    else:
                        status_area.text(f"ç”Ÿæˆå¤±è´¥: {str(e)}, æ­£åœ¨é‡è¯•...")
                        time.sleep(1)  # é‡è¯•å‰çŸ­æš‚ç­‰å¾…
        
        # æœ€ç»ˆéªŒè¯
        question_count_in_output = output.count('### é¢˜ç›®')
        st.session_state.generated_count = question_count_in_output
        
        if question_count_in_output >= question_count:
            st.success(f"æˆåŠŸç”Ÿæˆ{question_count_in_output}é“è¯•é¢˜ï¼")
            st.markdown(output, unsafe_allow_html=True)
            st.session_state.generated = True
            st.session_state.exam_content = output
        else:
            st.warning(f"å·²ç”Ÿæˆ{question_count_in_output}é“é¢˜ï¼ˆç›®æ ‡:{question_count}ï¼‰")
            st.markdown(output, unsafe_allow_html=True)
            st.session_state.exam_content = output
            
            # æ·»åŠ ç»§ç»­ç”ŸæˆæŒ‰é’®
            if st.button("ç»§ç»­ç”Ÿæˆå‰©ä½™é¢˜ç›®", key="continue_generate"):
                st.session_state.running = True
                st.session_state.generated = False
                st.rerun()
                
    except ImportError:
        st.error("æ¨¡å—æœªå®‰è£…ï¼Œè¯·å…ˆæ‰§è¡Œ: pip install ollama")
    except IndexError:
        st.error("å“åº”è§£æé”™è¯¯ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ ¼å¼")
    except Exception as e:
        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        if 'generated_count' in st.session_state:
            st.button("é‡è¯•ç”Ÿæˆ", on_click=lambda: st.session_state.update({
                "running": True,
                "generated": False
            }))
    finally:
            # æ˜¾ç¤ºå·²ç”Ÿæˆçš„å†…å®¹ï¼ˆä¸“ä¸šè¯•å·æ ¼å¼ï¼‰
            if st.session_state.generated and st.session_state.exam_content:
                with st.expander("ğŸ“ ç”Ÿæˆçš„è¯•å·å†…å®¹", expanded=True):
                    st.markdown(f"""
                    <div style='font-family: "Times New Roman", Times, serif;'>
                        <h2 style='text-align: center;'>{subject}è¯•å·</h2>
                        <hr style='border: 1px solid #000;'>
                        {st.session_state.exam_content}
                        <hr style='border: 1px solid #000;'>
                        <p style='text-align: right;'>æ€»åˆ†ï¼š100åˆ†</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    try:
                            # æŒä¹…åŒ–æ˜¾ç¤ºç”Ÿæˆçš„é¢˜ç›®å†…å®¹
                            st.markdown(f"""
                            <div style='font-family: "Times New Roman", Times, serif;'>
                                <h2 style='text-align: center;'>{subject}è¯•å·</h2>
                                <hr style='border: 1px solid #000;'>
                                {st.session_state.exam_content}
                                <hr style='border: 1px solid #000;'>
                                <p style='text-align: right;'>æ€»åˆ†ï¼š100åˆ†</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # ç”ŸæˆPDFä¸‹è½½æŒ‰é’®ï¼ˆä¸æ”¹å˜çŠ¶æ€ï¼‰
                            with st.container():
                                pdf_bytes = generate_pdf(st.session_state.exam_content, subject)
                                if pdf_bytes:
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.download_button(
                                            label="â¬‡ï¸ ä¸‹è½½è¯•å·(PDF)",
                                            data=pdf_bytes,
                                            file_name=f"{subject}_è¯•å·.pdf",
                                            mime="application/pdf",
                                            key="pdf_download"
                                        )
                                    
                                    outline = generate_outline(
                                        st.session_state.exam_content, 
                                        subject,
                                        outline_iterations
                                    )
                                    outline_bytes = generate_pdf(outline, f"{subject}è€ƒè¯•å¤§çº²")
                                    
                                    with col2:
                                        st.download_button(
                                            label="â¬‡ï¸ ä¸‹è½½è€ƒè¯•å¤§çº²(PDF)",
                                            data=outline_bytes,
                                            file_name=f"{subject}_è€ƒè¯•å¤§çº².pdf",
                                            mime="application/pdf",
                                            key="outline_download"
                                        )
                                else:
                                    st.error("PDFç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•")
                    except Exception as e:
                        st.error(f"ç”ŸæˆPDFæ—¶å‡ºé”™: {str(e)}")
                        st.button("é‡è¯•PDFç”Ÿæˆ", on_click=lambda: st.session_state.update({"already_displayed": False}))

# è€ƒè¯•å¤§çº²ç”Ÿæˆå‡½æ•°
def generate_outline(exam_content, subject):
    # æå–é¢˜ç›®ä¿¡æ¯
    questions = re.findall(r'### é¢˜ç›®\d+\n\*\*é¢˜å‹\*\*:(.+?)\n\*\*é¢˜ç›®å†…å®¹\*\*:(.+?)\n\*\*ç­”é¢˜è¦æ±‚\*\*:(.+?)\n\*\*åˆ†å€¼\*\*:(.+?)\n', exam_content, re.DOTALL)
    
    # æ„å»ºå¤§çº²å†…å®¹
    outline = f"{subject}è€ƒè¯•å¤§çº²\n\n"
    outline += "ä¸€ã€è€ƒè¯•æ¦‚å†µ\n"
    outline += f"ç§‘ç›®: {subject}\n"
    outline += f"é¢˜ç›®æ€»æ•°: {len(questions)}\n"
    outline += "æ€»åˆ†: 100åˆ†\n\n"
    
    outline += "äºŒã€é¢˜å‹åˆ†å¸ƒ\n"
    type_counts = {}
    for q in questions:
        q_type = q[0].strip()
        type_counts[q_type] = type_counts.get(q_type, 0) + 1
    for t, count in type_counts.items():
        outline += f"{t}: {count}é¢˜\n"
    outline += "\n"
    
    outline += "ä¸‰ã€çŸ¥è¯†ç‚¹åˆ†å¸ƒ\n"
    topics = get_subject_topics(subject)
    outline += ", ".join(topics) + "\n\n"
    
    outline += "å››ã€é¢˜ç›®è¦æ±‚\n"
    for i, q in enumerate(questions, 1):
        outline += f"{i}. {q[1].strip()} (åˆ†å€¼: {q[3].strip()})\n"
    
    outline += "\näº”ã€è¯„åˆ†æ ‡å‡†\n"
    outline += "1. æŒ‰æ­¥éª¤ç»™åˆ†\n"
    outline += "2. ç­”æ¡ˆå‡†ç¡®å®Œæ•´\n"
    outline += "3. ç¬¦åˆå­¦ç§‘è§„èŒƒ\n"
    
    return outline

# æ˜¾ç¤ºç”Ÿæˆæç¤º
with st.expander("æŸ¥çœ‹ç”Ÿæˆæç¤º"):
    st.code(f"ç³»ç»Ÿæç¤º: {system_prompt}")
    st.code(f"ç”¨æˆ·è¾“å…¥: {user_prompt}")



# å®‰å…¨æç¤º
st.warning("æ³¨æ„ï¼šå½“å‰ä½¿ç”¨ç¡¬ç¼–ç APIå¯†é’¥ï¼Œè¯·å‹¿åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨æ­¤é…ç½®")
